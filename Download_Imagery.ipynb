{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Landsat upgrade\n",
    "\n",
    "1. download sentinel/landsat\n",
    "2. split into 400 pix by 400 pix tiles\n",
    "3. use lat/lon bounds for each tile to split coincident landsat image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## libraries\n",
    "import sys\n",
    "import datacube\n",
    "from odc.ui import with_ui_cbk\n",
    "\n",
    "# plotting\n",
    "from matplotlib import pyplot as plt\n",
    "# maths\n",
    "import numpy as np\n",
    "# save png images\n",
    "import imageio\n",
    "import csv\n",
    "\n",
    "## DEA scripts\n",
    "sys.path.append(\"Scripts\")\n",
    "\n",
    "#from dea_datahandling import load_ard\n",
    "from DEAPlotting import rgb\n",
    "from multiprocessing import Pool\n",
    "from IPython.display import clear_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Datacube connection\n",
    "dc = datacube.Datacube(app=\"Sentinel_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for making image in a loop\n",
    "\n",
    "product=\"s2a_ard_granule\"\n",
    "bands = [\"nbart_blue\", \"nbart_green\", \"nbart_red\"]\n",
    "\n",
    "csvfile = 'Points wgs rand 2k - Points wgs rand 2k.csv'\n",
    "count=0\n",
    "list_of_chips = []\n",
    "x_space = -0.051\n",
    "y_space = -0.034\n",
    "maxcount = 20\n",
    "\n",
    "with open(csvfile) as csv_file:\n",
    "    readCSV = csv.reader(csv_file, delimiter=',')\n",
    "    for row in readCSV:\n",
    "        if row[7]=='1' and row[6]!='12':\n",
    "            \n",
    "            #print(row)\n",
    "            x_min = float(row[3])\n",
    "            y_min = float(row[4])\n",
    "            x_max = float(row[3])-x_space\n",
    "            y_max = float(row[4])+y_space\n",
    "            uid = row[0]\n",
    "            x=(x_min,x_max)\n",
    "            y=(y_min,y_max)\n",
    "            #xlist.append(x)\n",
    "            #ylist.append(y)\n",
    "            year = row[5]\n",
    "            month = int(row[6])\n",
    "            start_month = str(f\"{month:02d}\")\n",
    "            end_month = str(f\"{(month+1):02d}\")\n",
    "            start_date = (year+\"-\"+start_month)\n",
    "            end_date = (year+\"-\"+end_month)\n",
    "            date_range = start_date,end_date\n",
    "            #my_tlist.append(date_range)\n",
    "            \n",
    "            \n",
    "\n",
    "            \n",
    "            #print(full_list)\n",
    "            list_of_chips.append([uid,date_range,x,y])\n",
    "            #print(uid,',')\n",
    "            \n",
    "            \n",
    "            count+=1\n",
    "            if count>maxcount:\n",
    "                break\n",
    "#print(tlist[0:3], xlist[0:3], ylist[0:3])\n",
    "\n",
    "#idlist = range(len(my_tlist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list_of_chips\n",
    "verbose=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def chipper(chip):\n",
    "    \n",
    "    \n",
    "#for chip in list_of_chips:\n",
    "\n",
    "\n",
    "    idlist = chip[0]\n",
    "    time = chip[1]\n",
    "    x = chip[2]\n",
    "    y = chip[3]\n",
    "    \n",
    "    # Create a query object\n",
    "    if verbose:\n",
    "        print(x)\n",
    "        print(y)\n",
    "        print(time)\n",
    "    query = {\n",
    "        \"x\": x,\n",
    "        \"y\": y,\n",
    "        \"time\": time,\n",
    "        \"output_crs\": \"EPSG:3577\",\n",
    "        \"resolution\": (-10, 10),\n",
    "        \"group_by\": \"solar_day\",\n",
    "    }\n",
    "    \n",
    "    ## download ard granule\n",
    "    ds = dc.load(\n",
    "        product=product,\n",
    "        measurements = bands,\n",
    "        progress_cbk = with_ui_cbk(),\n",
    "        **query\n",
    "    )\n",
    "    if verbose:\n",
    "        print(ds)\n",
    "    if len(ds.sizes)==0:\n",
    "        print(\"WARNING: NO DATA FOR TIME RANGE\",time)\n",
    "        #continue\n",
    "        \n",
    "    time_step_count=0\n",
    "    if len(ds.sizes)!=0:\n",
    "        for time_step in ds.time:\n",
    "            \n",
    "            img = np.moveaxis(ds[['nbart_red', 'nbart_green', 'nbart_blue']].isel(time=time_step_count).to_array().values,0,2)\n",
    "            #print(img.shape)\n",
    "            #np.flip(img,axis=0)# flip y axis\n",
    "            # convert image to uint8 from uint16\n",
    "            #print(np.min(img),np.max(img))\n",
    "            img[img<0] = 0\n",
    "            img = (img * (255./ 4000.)).astype(np.uint8)\n",
    "            img[img>255] = 255\n",
    "            ## Cut to 400x400\n",
    "            n_y,n_x,_ = np.shape(img)\n",
    "\n",
    "            dim_max=400\n",
    "            assert n_x > dim_max, \"ERR: X DIM IS < 400\"\n",
    "            assert n_y > dim_max, \"ERR: Y DIM IS < 400\"\n",
    "\n",
    "            x_cut = float(dim_max)/n_x\n",
    "            y_cut = float(dim_max)/n_y\n",
    "            new_x_1 = x[0] + (x[1]-x[0])*x_cut\n",
    "\n",
    "\n",
    "\n",
    "            new_y_1 = y[0] + (y[1]-y[0])*y_cut\n",
    "            img_cut = img[:dim_max,:dim_max,:]\n",
    "\n",
    "            if verbose:\n",
    "                print(img.shape, img_cut.shape)\n",
    "                print(x, '->', x[0], new_x_1)\n",
    "                print(y, '->', y[0], new_y_1)\n",
    "\n",
    "            #print(np.min(img),np.max(img))\n",
    "            fname=\"sentinel_images/\"+str(idlist)+\"sentinel\"+str(time_step_count)+\".png\"\n",
    "            imageio.imwrite(fname,img_cut)\n",
    "            if verbose:\n",
    "                print(\"INFO: Saved figure: \",fname)\n",
    "    \n",
    "    \n",
    "    ## download landsat equivalent\n",
    "    query = {\n",
    "        \"x\": (x[0], new_x_1),\n",
    "        \"y\": (y[0], new_y_1),\n",
    "        \"time\": time,\n",
    "        \"output_crs\": \"EPSG:3577\",\n",
    "        \"resolution\": (-25, 25),\n",
    "        \"group_by\": \"solar_day\",\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "    ## download ard granule\n",
    "    #lsbands = ['Visible']\n",
    "    ds2 = dc.load(\n",
    "        product='ga_ls8c_ard_3',\n",
    "        measurements = bands,\n",
    "        progress_cbk = with_ui_cbk(),\n",
    "        **query\n",
    "    )\n",
    "    \n",
    "    if verbose:\n",
    "        print(ds2)\n",
    "    if len(ds2.sizes)==0:\n",
    "        print(\"WARNING: NO DATA FOR TIME RANGE\",time)\n",
    "        #continue\n",
    "        \n",
    "    time_step_count=0\n",
    "    if len(ds2.sizes)!=0:\n",
    "        for time_step in ds2.time:\n",
    "            lsimg = np.moveaxis(ds2[['nbart_red', 'nbart_green', 'nbart_blue']].isel(time=time_step_count).to_array().values,0,2)\n",
    "\n",
    "            lsimg[lsimg<0] = 0\n",
    "            lsimg = (lsimg * (255./ 4000.)).astype(np.uint8)\n",
    "            lsimg[lsimg>255] = 255\n",
    "\n",
    "\n",
    "            if verbose:\n",
    "                print(lsimg.shape, lsimg.shape)\n",
    "\n",
    "\n",
    "            lsfname=\"sentinel_images/\"+str(idlist)+\"land_sat_TS\"+str(time_step_count)+\".png\"\n",
    "            imageio.imwrite(lsfname,lsimg)\n",
    "            time_step_count=+1\n",
    "        if verbose:\n",
    "            print(\"INFO: Saved figure: \",lsfname)\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.moveaxis(ds2[['nbart_red', 'nbart_green', 'nbart_blue']].isel(time=2).to_array().values,0,2)\n",
    "#time_steps = ds2.time\n",
    "#print(ds2.time)\n",
    "#for time_step in ds.time:\n",
    "    #print(time_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: NO DATA FOR TIME RANGE ('2016-02', '2016-03')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c06e6570213e426d82a1875882d19e2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Label(value=''), Label(value='')), layout=Layout(justify_content='space-between'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2789616bd74402893ed844adf7bad38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Label(value=''), Label(value='')), layout=Layout(justify_content='space-between'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OperationalError",
     "evalue": "(psycopg2.OperationalError) SSL error: wrong version number\n\n[SQL: SELECT agdc.dataset_type.id, agdc.dataset_type.name, agdc.dataset_type.metadata, agdc.dataset_type.metadata_type_ref, agdc.dataset_type.definition, agdc.dataset_type.added, agdc.dataset_type.added_by \nFROM agdc.dataset_type ORDER BY agdc.dataset_type.name ASC]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.6/dist-packages/sqlalchemy/engine/base.py\", line 1246, in _execute_context\n    cursor, statement, parameters, context\n  File \"/usr/local/lib/python3.6/dist-packages/sqlalchemy/engine/default.py\", line 588, in do_execute\n    cursor.execute(statement, parameters)\npsycopg2.OperationalError: SSL error: wrong version number\n\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 44, in mapstar\n    return list(map(*args))\n  File \"<ipython-input-8-24722507d74a>\", line 31, in chipper\n    **query\n  File \"/usr/local/lib/python3.6/dist-packages/datacube/api/core.py\", line 300, in load\n    datasets = self.find_datasets(product=product, like=like, ensure_location=True, **query)\n  File \"/usr/local/lib/python3.6/dist-packages/datacube/api/core.py\", line 340, in find_datasets\n    return list(self.find_datasets_lazy(**search_terms))\n  File \"/usr/local/lib/python3.6/dist-packages/datacube/api/core.py\", line 354, in find_datasets_lazy\n    query = Query(self.index, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/datacube/api/query.py\", line 82, in __init__\n    unknown_keys = remaining_keys - set(index.datasets.get_field_names())\n  File \"/usr/local/lib/python3.6/dist-packages/datacube/index/_datasets.py\", line 348, in get_field_names\n    types = self.types.get_all()\n  File \"/usr/local/lib/python3.6/dist-packages/datacube/index/_products.py\", line 369, in get_all\n    return (self._make(record) for record in connection.get_all_products())\n  File \"/usr/local/lib/python3.6/dist-packages/datacube/drivers/postgres/_api.py\", line 909, in get_all_products\n    PRODUCT.select().order_by(PRODUCT.c.name.asc())\n  File \"/usr/local/lib/python3.6/dist-packages/sqlalchemy/engine/base.py\", line 982, in execute\n    return meth(self, multiparams, params)\n  File \"/usr/local/lib/python3.6/dist-packages/sqlalchemy/sql/elements.py\", line 293, in _execute_on_connection\n    return connection._execute_clauseelement(self, multiparams, params)\n  File \"/usr/local/lib/python3.6/dist-packages/sqlalchemy/engine/base.py\", line 1101, in _execute_clauseelement\n    distilled_params,\n  File \"/usr/local/lib/python3.6/dist-packages/sqlalchemy/engine/base.py\", line 1250, in _execute_context\n    e, statement, parameters, cursor, context\n  File \"/usr/local/lib/python3.6/dist-packages/sqlalchemy/engine/base.py\", line 1476, in _handle_dbapi_exception\n    util.raise_from_cause(sqlalchemy_exception, exc_info)\n  File \"/usr/local/lib/python3.6/dist-packages/sqlalchemy/util/compat.py\", line 398, in raise_from_cause\n    reraise(type(exception), exception, tb=exc_tb, cause=cause)\n  File \"/usr/local/lib/python3.6/dist-packages/sqlalchemy/util/compat.py\", line 152, in reraise\n    raise value.with_traceback(tb)\n  File \"/usr/local/lib/python3.6/dist-packages/sqlalchemy/engine/base.py\", line 1246, in _execute_context\n    cursor, statement, parameters, context\n  File \"/usr/local/lib/python3.6/dist-packages/sqlalchemy/engine/default.py\", line 588, in do_execute\n    cursor.execute(statement, parameters)\nsqlalchemy.exc.OperationalError: (psycopg2.OperationalError) SSL error: wrong version number\n\n[SQL: SELECT agdc.dataset_type.id, agdc.dataset_type.name, agdc.dataset_type.metadata, agdc.dataset_type.metadata_type_ref, agdc.dataset_type.definition, agdc.dataset_type.added, agdc.dataset_type.added_by \nFROM agdc.dataset_type ORDER BY agdc.dataset_type.name ASC]\n(Background on this error at: http://sqlalche.me/e/e3q8)\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-7db6f2873a06>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchipper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist_of_chips\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreturned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         '''\n\u001b[0;32m--> 266\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstarmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    642\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOperationalError\u001b[0m: (psycopg2.OperationalError) SSL error: wrong version number\n\n[SQL: SELECT agdc.dataset_type.id, agdc.dataset_type.name, agdc.dataset_type.metadata, agdc.dataset_type.metadata_type_ref, agdc.dataset_type.definition, agdc.dataset_type.added, agdc.dataset_type.added_by \nFROM agdc.dataset_type ORDER BY agdc.dataset_type.name ASC]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-1:\n",
      "Process ForkPoolWorker-4:\n",
      "Process ForkPoolWorker-2:\n",
      "Process ForkPoolWorker-3:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "pool = Pool(4)\n",
    "pool.map(chipper, list_of_chips)\n",
    "pool.close()\n",
    "pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
